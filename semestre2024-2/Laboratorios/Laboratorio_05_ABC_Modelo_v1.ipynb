{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnngD5pxRMVa"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CienciaDatosUdea/002_EstudiantesAprendizajeEstadistico/blob/main/semestre2024-2/Laboratorios/Laboratorio_05_ABC_Modelo_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ti1117tZ_pVK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrGkd94IAUhO"
   },
   "source": [
    "# Problema:\n",
    "\n",
    "El dataset de casas de California. Es un conjunto de datos que contiene información sobre los precios medios de las viviendas y otras características de los distritos de California, basado en el censo de 1990.\n",
    "\n",
    "\n",
    "\n",
    "**longitude**: es la longitud del centroide del distrito, expresada en grados. Esta variable indica la posición geográfica del distrito en el mapa.\n",
    "\n",
    "**latitude**: es la latitud del centroide del distrito, expresada en grados. Esta variable también indica la posición geográfica del distrito en el mapa.\n",
    "\n",
    "**housing_median_age**: es la edad media de las casas en el distrito, expresada en años. Esta variable refleja el estado y la antigüedad de las viviendas en el distrito.\n",
    "\n",
    "**total_rooms**: es el número total de habitaciones en el distrito, sin distinguir entre tipos de habitaciones. Esta variable refleja el tamaño y la capacidad de las viviendas en el distrito.\n",
    "\n",
    "**total_bedrooms**: es el número total de dormitorios en el distrito. Esta variable refleja el número de espacios destinados al descanso en las viviendas del distrito.\n",
    "\n",
    "**population**: es el número de personas que viven en el distrito. Esta variable refleja la densidad y la demanda de vivienda en el distrito.\n",
    "\n",
    "\n",
    "**households**: es el número de hogares en el distrito. Un hogar es un grupo de personas que residen dentro de una casa. Esta variable refleja la estructura y la composición de las familias en el distrito.\n",
    "\n",
    "\n",
    "**median_income**: es el ingreso medio por hogar en el distrito, expresado en miles de dólares ($1000). Esta variable refleja el nivel socioeconómico y el poder adquisitivo de los habitantes del distrito.\n",
    "\n",
    "\n",
    "**median_house_value**: es el valor medio de las casas en el distrito, expresado en cientos de miles de dólares ($100,000). Esta variable es la variable objetivo que se quiere predecir. Refleja el precio y la calidad de las viviendas en el distrito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts5ISXqDAOLY"
   },
   "source": [
    "# 1.0 Análisis del data frame\n",
    "\n",
    "1. Leer el data frame en formato csv en la dirección https://raw.githubusercontent.com/hernansalinas/Curso_aprendizaje_estadistico/main/datasets/Sesion_07_housing.csv\n",
    "\n",
    "2. Entender  el estado de los datos, para ello puedo emplear los comandos básicos del pandas\n",
    "\n",
    "  ```python\n",
    "  df.info()\n",
    "  df.describe()\n",
    "  df.isnull().sum()\n",
    "  df.isna().sum()\n",
    "```\n",
    "Estos dos últimos son equivalentes.\n",
    "\n",
    "3. Determinar los elementos únicos dentro de la columna ocean_proximity.\n",
    "\n",
    "\n",
    "4. Para las columnas\n",
    "\n",
    "```python\n",
    "cols = [\"housing_median_age\",\t\"total_rooms\",\t\"total_bedrooms\",\t\"population\",\t\"households\",\t\"median_income\",\t\"median_house_value\"]\n",
    "```\n",
    "\n",
    "Determinar el promedio de cada una de las columnas asociado a cada elementos unico de ocean_proximity, intenta con la operación groupby.\n",
    "\n",
    "\n",
    "5. Construye un histograma para cada columna, puede emplear la libreria de seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hq5950GCKKj"
   },
   "source": [
    "### [Diagrama de caja](https://en.wikipedia.org/wiki/Box_plot)\n",
    "\n",
    "\n",
    "### Diagrama de caja\n",
    "\n",
    "![box](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/800px-Boxplot_vs_PDF.svg.png)\n",
    "\n",
    "\n",
    "\n",
    "### Interpretación de un diagrama de caja\n",
    "\n",
    "- Desde el minimo al valor más bajo de la caja: primer cuartil, 25% de los datos\n",
    "- Desde el valor más bajo de la caja hasta la mediana: segundo cuartil, 25% de los datos\n",
    "- Desde la mediana hasta el valor mas alto de la caja : tercer cuartil, 25% de los datos\n",
    "- Desde el valor mas alto de la caja hasta el máximo: Cuarto  cuartil, 25% de los datos\n",
    "\n",
    "\n",
    "El rango intercuartil $IQR = Q_3-Q_1$ permite definir que datos pueden ser atípicos, basado en los siguientes limites:\n",
    "\n",
    "$Max = Q3 + 1.5IQR$\n",
    "\n",
    "$Min = Q1 - 1.5IQR$\n",
    "\n",
    "\n",
    "\n",
    "El cuartil puede ser determinado como sigue:\n",
    "\n",
    "Para calcular los cuartiles de una lista de números:\n",
    "\n",
    "- Ordenar los números de menor a mayor.\n",
    "- Calcular la posición de cada cuartil usando la fórmula: Q = a (N+1) / 4, donde Q es la posición del cuartil, a es el número del cuartil (1, 2 o 3), y N es el número total de datos.\n",
    "- Si la posición del cuartil es un número entero, el valor del cuartil es el dato que está en esa posición.\n",
    "- Si la posición del cuartil es un número decimal, el valor del cuartil se interpola usando la fórmula: Q = x + d (y - x), donde Q es el valor del cuartil, x es el dato anterior a la posición del cuartil, y es el dato posterior a la posición del cuartil, y d es la parte decimal de la posición del cuartil.\n",
    "\n",
    "\n",
    "Veamos un ejemplo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rU9xGFJDDWIu",
    "outputId": "29ed3d31-db27-4f49-b2e6-aa247cd5bf85"
   },
   "outputs": [],
   "source": [
    "T = np.array([52, 57, 57, 58, 63, 66, 66, 67, 67, 68, 69, 70, 70, 70, 70, 72, 73, 75, 75, 76, 76, 78, 79, 89])\n",
    "Tsort = np.sort(T)\n",
    "print(len(T))\n",
    "print(f\"T sort:{Tsort}\")\n",
    "len(T)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "K2IsmwysCJf2",
    "outputId": "73d71b25-8735-4630-9ff4-d14ab7c360fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "IQR=9\n",
    "max_ = 75 + 1.5*IQR\n",
    "min_ = 66 - 1.5*IQR\n",
    "print(max_)\n",
    "print(min_)\n",
    "plt.boxplot(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWYWxa-uH9WI"
   },
   "source": [
    "7. Empleando el siguiente código realiza el gráfico boxplot,\n",
    "```python\n",
    "#draw boxplot\n",
    "df.boxplot(column=\"median_house_value\", by='ocean_proximity', sym = 'k.', figsize=(18,6))\n",
    "#set title\n",
    "plt.title('Boxplot for comparing price per living space for each city')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_BCSoJcIM_i"
   },
   "source": [
    "8. Determina la matrix de correlación.\n",
    "\n",
    "### [Matrix de correlación](https://en.wikipedia.org/wiki/Correlation)\n",
    "\n",
    "¿Como se determina la matrix de correlación?\n",
    "\n",
    "![Matrix de correlación](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1920px-Correlation_examples2.svg.png)\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = \"coolwarm\", center=0)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwsUEbJHIf9e"
   },
   "source": [
    "9. con las columnas, realiza un grafico pairplot empleando seaborn  de python.\n",
    "```python\n",
    "cols = [\"median_house_value\", \"median_income\", \"total_rooms\",\"housing_median_age\"]\n",
    "```\n",
    "\n",
    "10. Realizaun scatter plot con la libreria sea born de python, el color del grafico puede ser empleado con la columna median_house_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEFoB673I5r1"
   },
   "source": [
    "#2.0 Preparacion del data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVzMB3_JJK7d"
   },
   "source": [
    "## Evitar el data *Snooping bias*.\n",
    "\n",
    "En algunos casos se sugiere dividir los datos en entrenamiento y test desde el principio dado que el cerebro puede sobreajustar el dataset y los resultados no significativos se pueden volver significativos. El procedimiento correcto es probar cualquier hipótesis en un conjunto de datos que no se utilizó para generar las hipótesis inicial.\n",
    "\n",
    "\n",
    "## *Sampling bias*\n",
    "\n",
    "Si el dataset es lo suficientemente grande un muestreo aleatorio de la muestra puede ser considerado, sin embargo si la muestra es pequena se debe garantizar homegeniedad en el dataset de entrenamiento.\n",
    "\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Por ejemplo, la población de EE. UU. esta compuesto por un 51,3 % de mujeres y un 48,7 % de hombres, por lo que una encuesta bien realizada en EEUU\n",
    "trata de mantener esta proporción en la muestra: 513 mujeres y 487 hombres. Esto se llama muestreo estratificado(stratified sampling): la población se divide en subgrupos homogéneos llamados estratos(strata), y se muestrea el número correcto de instancias de cada estrato para garantizar que el\n",
    "El conjunto de prueba es representativo de la población general. Si usaran muestras puramente aleatorias, habría alrededor del 12% de posibilidades de muestrear un conjunto de prueba sesgado con menos del 49% de mujeres o más del 54% de mujeres. De cualquier manera, los resultados de la encuesta serían\n",
    "significativamente sesgada.\n",
    "\n",
    "\n",
    "11. ¿Las siguiente linea es adecuada para separar el dataframe en datos de entrenamiento de test?, ¿que pasa en la división de los datos?\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ¿Es significativa la muestra que se esta considerando?\n",
    "train_set, test_set \\\n",
    "  = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "12. División del dataset en grupos:\n",
    "\n",
    "\n",
    "La siguiente división puede ser realizada  basada en la experticie de lo que se esta analizando, y sobre ello se debe tomar una muestra significativa. Una posible solución al problema puede ser el siguiente:\n",
    "\n",
    "```python\n",
    "df[\"income_cat\"] = pd.cut(df[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "\n",
    "df.income_cat.hist()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "La forma automatica de realizar la división puede ser la siguiente:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df, df[\"income_cat\"]):\n",
    "  strat_train_set = df.loc[train_index]\n",
    "  strat_test_set = df.loc[test_index]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Analiza las siguiente lineas de código y saca conclusiones referente a las proporciones del dataset.\n",
    "\n",
    "```python\n",
    "df[\"income_cat\"].value_counts() / len(df)\n",
    "\n",
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)\n",
    "\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)\n",
    "\n",
    "\n",
    "train_set, test_set \\\n",
    "  = train_test_split(df, test_size = 0.2, random_state = 7)\n",
    "\n",
    "train_set[\"income_cat\"].value_counts() / len(train_set)\n",
    "```\n",
    "\n",
    "un comparativo general puede ser estructurado de la siguente forma, analiza  los errores:\n",
    "\n",
    "```python\n",
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(df),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] =abs( 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100)\n",
    "compare_props[\"Strat. %error\"] =abs( 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfk25GjkLWtD"
   },
   "source": [
    "13. Puedes agregar nuevas variables al dataframe para el análisis, por ejemplo:\n",
    "```python\n",
    "df_train[\"rooms_per_household\"] = df_train[\"total_rooms\"]/df_train[\"households\"]\n",
    "df_train[\"bedrooms_per_room\"] = df_train[\"total_bedrooms\"]/df_train[\"total_rooms\"]\n",
    "df_train[\"population_per_household\"]=df_train[\"population\"]/df_train[\"households\"]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Limpieza de datos\n",
    "\n",
    "Lo que sigue son códigos que pueden servir para limpiar los datos.\n",
    "\n",
    "```python\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "#df_train.dropna(subset=[\"total_bedrooms\"]) #Eliminar los nan\n",
    "#df_train.drop(\"total_bedrooms\", axis=1)  # Eliminar la columna\n",
    "median = df_train[\"total_bedrooms\"].median()\n",
    "q=df_train[\"total_bedrooms\"].fillna(median).copy()\n",
    "\n",
    "\n",
    "q=pd.DataFrame(q)\n",
    "\n",
    "q.isnull().sum()\n",
    "\n",
    "```\n",
    "\n",
    "##imputer\n",
    "\n",
    "Forma automática para tratar los datos (Asegurate de trabajar con las columnas numéricas):\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "#imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "df_train_num = df_train.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "imp_mean = SimpleImputer( strategy='mean')\n",
    "\n",
    "imp_mean.fit(df_train_num)\n",
    "\n",
    "imp_mean.statistics_\n",
    "```\n",
    "\n",
    "14. Compara las siguientes variables:\n",
    "```python\n",
    "imp_mean.statistics_\n",
    "df_train_num.median()\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "Constuye la matriz de características:\n",
    "\n",
    "X = imp_mean.transform(df)\n",
    "housing_tr = pd.DataFrame(X, columns=df_train_num.columns)\n",
    "```\n",
    "\n",
    "\n",
    "# Manejo de texto y atributos categóricos\n",
    "15.  ¿Qué realizan las siguientes lineas de código?\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df_train[\"ocean_proximity\"].unique()\n",
    "housing_cat=df_train[[\"ocean_proximity\"]]\n",
    "housing_cat\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse_output=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "print(housing_cat_1hot)\n",
    "print(cat_encoder.categories_)\n",
    "\n",
    "\n",
    "df_cat_1hot = pd.DataFrame(housing_cat_1hot, columns = cat_encoder.categories_[0])\n",
    "\n",
    "housing_tr_ = housing_tr.join(df_cat_1hot)\n",
    "```\n",
    "\n",
    "\n",
    "# Escalamiento de variables\n",
    "\n",
    "16. Las variables pueden ser escaladas como sigue:\n",
    "\n",
    "```python\n",
    "\n",
    "cols=[\"longitude\", \"latitude\",\t\"housing_median_age\",\t\"total_rooms\",\\\n",
    "      \"total_bedrooms\",\t\"population\",\t\"households\",\t\"median_income\",\\\n",
    "      \"<1H OCEAN\",\t\"INLAND\",\t\"ISLAND\",\t\"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "\n",
    "\n",
    "housing_scale=housing_tr_[cols]\n",
    "housing_scale\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(housing_scale)\n",
    "\n",
    "X = scaler.transform(housing_scale)\n",
    "\n",
    "\n",
    "housing_prepared = pd.DataFrame(X, columns = housing_scale.columns)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "17. Para todos los pasos anteriores, contruye ordenadamente los pasos limpieza, escalamiento de variables, manejo de texto y atributos categóricos para tener el data frame listo para el análisis. Recuerda dividir el data frame en datos de entrenamiento y de test con la correcta estractificación. Genera dos data frame: housing_train, housing_test, cada una, debe tener las caracteristicas y los datos etiquetados.\n",
    "\n",
    "1. ¿que puede concluir respecto al modelo empleado?\n",
    "2. ¿El modelo de regresión lineal es valido para lo construido,\n",
    "3. ¿qué informacion nos da el score?\n",
    "4. ¿Puede ser ajustado a otro modelo?\n",
    "5. ¿Como puede autmatizar todo el proceso empleando pipelines?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
